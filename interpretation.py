from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda

#from langchain.vectorstores import FAISS
from langchain_community.vectorstores import FAISS

import pandas as pd
pd.set_option('display.max_colwidth', None)
pd.set_option('display.max_rows', None)
from ._settings import get_llm, get_llm_embedding
import json, re, ast
from types import SimpleNamespace


def llm_answer(prompt,question):
    """
    Generates an answer using a predefined prompt template and a given question by calling an LLM (Large Language Model).

    Args:
        prompt (str): The input prompt template, usually containing system instructions or task descriptions.
        question (str): The user's question, which the LLM will use to generate a response.

    Returns:
        str: The answer generated by the LLM.
    """        
    system_message_prompt = SystemMessagePromptTemplate.from_template(prompt)
    human_message_prompt = HumanMessagePromptTemplate.from_template("{question}")
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    llm = get_llm()
    #chain = LLMChain(llm=llm, prompt=chat_prompt)
    #answer = chain.run(question)
    chain = chat_prompt | llm
    print("Now generating answer ... \n")
    answer = chain.invoke({"question": question})
    return answer.content

def verify_grn(trajectory_path,tf_list,verified_gene,regulon,u_question=None):
    if u_question is None:
        question = "Is the red path in the trajectory graph correct? Can it be explained by the TF and its regulons?"
    else:
        question = translator(u_question)

    prompt = """###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports, think it step by step.

        ###Task###: Use the provided information to help user verify the correctness of the red path in graph. Write as much as you can, do not write the operations you are going to perform; think of question step by step.

        ###Context###: Whole graph: {context}
        1. User has a cell development trajectory graph, obtained as follows: 1) The trajectory inference used the PAGA algorithm to obtain the PAGA results. 2) Then, by referencing node pairs that appear in the PAGA results within our biological knowledge graph, we supplemented the PAGA results, ultimately constructing the input graph.
        2. In this graph, the following information can be obtained: 1) Circular/Ellipse nodes represent data from the original RNAseq dataset, and gray hexagonal nodes represent data from our biological knowledge graph; 2) Green edges with arrows represent developmental trajectories that can be found in the knowledge graph, while red edges without arrows represent developmental trajectories that are not recorded in the graph but were inferred by the PAGA algorithm from the actual dataset.
        2. There are three input list: {tf_list}: contains the name of the transcription factor at motif which is most involved in gene regulatory network.
        {verified_gene} contains the gene name from regulon but also has been proven by experiment that can be regulated by transcription factor.
        {regulon} contains all gene names calculated by SCENIC method that might be regulated by transcription factor.

        ###Instructions###:
        1. From a biologist's perspective, analyse all provided information in your mind.
        2. Verify the develop path after understand the biological function of TF and its regulons, answer the question: can user trust the develop path from PAGA? If user can't trust it, provide the correct develop path by using the nodes in trajectory graph.
        3. Whole analysis can be interpreted from multiple angles, such as the details of this transcription factor, the details of proven genes, the function of this TF-Regulon, and so on. Give details as much as you can.
        4. Avoiding to print all the user input content, take more attention into analysis.
        
        ###Question###: {question}
        """
        
    model = get_llm()
    prompt = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": RunnableLambda(lambda _: trajectory_path), "tf_list": RunnableLambda(lambda _: tf_list), "verified_gene": RunnableLambda(lambda _: verified_gene), "regulon": RunnableLambda(lambda _: regulon), "question": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    #result = llm_answer(prompt,question)
    return result


# 一个通用的解读prompt
def general_interpret(*args, **kwargs):
    import pandas as pd
    result_str = ""
    result_templete = "{}:\n{}\n"
    for i, x in enumerate(args):
        # 如果是 DataFrame，使用 to_string() 确保完整显示
        if isinstance(x, pd.DataFrame):
            x_str = x.to_string()
        else:
            x_str = str(x)
        result_str += result_templete.format(f'result{i}', x_str)
    for x, y in kwargs.items():
        if isinstance(y, pd.DataFrame):
            y_str = y.to_string()
        else:
            y_str = str(y)
        result_str += result_templete.format(x, y_str)
    #print(result_str)
    return result_str

def interpret_results(task = '', *args, **kwargs):
    if task == '':
        task = "general interpretation"
    
    result = general_interpret(*args, **kwargs)
    prompt = f"""
As an expert bioinformatics analyst, you will recieve an analysis result of a bioinformatics task. please give a comprehensive interpretation of the following results from three aspects:
1. Reasoning the analysis result:
- point out the key evidence chain and its statistical significance that support the conclusion;
- explain the reasonability of the analysis result by the context and the analysis result.
- sort out the most valuable conclusion from the analysis result.

2. Exploring new biological hypotheses:
- point out the contradiction and the complement of the analysis result with the context.
- try propose new biological hypotheses that can be validated by experiments.
- speculate the clinical/translational medical significance of the analysis result.

3. Advicing for following analysis:
- advices for following analysis step, etc, gene enrichment analysis, drug repurposing analysis, etc.
- advices research subject for following analysis step, etc, a specific cell type, a specific gene, a specific pathway, etc.


## Rules:
1. the analysis result might contains single cell omics analysis result and a queried result from biological knowledge graph. try to understand each variable by the context and variable name.
2. the analysis result might be a string, list, dict, dataframe, anndata object, networkx graph, etc.
3. write the interpretation in a clear and concise manner, with a professional and academic tone.
4. the interpretation should be in a three-part structure, each part contains 3-5 points.
5. if some interpretation aspects is not useful, you can ignore some of specific steps.
6. make the interpretation breif and clear.

task: {task}
analysis result: 

{result}
"""
    model = get_llm()
    prompt = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": RunnableLambda(lambda _: result), "task": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(task)
    return result

def analyse_grn(tf_list,verified_gene,regulon,u_question=None,u_prompt=None,sub_task=None):
    """
    Analyzes a gene regulatory network and generates a detailed report on specific transcription factors (TFs) and their regulated genes.

    Args:
        tf_list (list): A list containing information about transcription factors.
        verified_gene (list): A list of regulatory targets that have been validated in known databases.
        regulon (list): A list of potential target genes regulated by transcription factors, inferred using the SCENIC method.
        u_question (str, optional): A user-defined question. Defaults to "Analyse the TF and its regulon" if not provided.
        u_prompt (str, optional): A user-defined prompt. Defaults to a predefined analysis report template if not provided.
        sub_task (str, optional): A user-defined subtask name, used for customizing the prompt content.

    Returns:
        str: A generated analysis report containing detailed insights into transcription factors and their gene regulatory relationships.
    """
    if u_question is None:
        question = "Analyse the TF and its regulon"
    else:
        question = translator(u_question)

    if u_prompt is None and sub_task is None:
        prompt = """###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

        ###Task###: Use the provided information to inform user that the regulatory relationship between transcription factor and some genes in regulons has already verified by experiment. Write as much as you can, do not write the operations you are going to perform; think of question step by step.

        ###Context###: There are three input list: #tf_list#:%s contains the name of the transcription factor at motif which is most involved in gene regulatory network.
        #verified_gene#:%s contains the gene name from regulon but also has been proven by experiment that can be regulated by transcription factor.
        #regulon#:%s contains all gene names calculated by SCENIC method that might be regulated by transcription factor.

        ###Instructions###:
        1. From a biologist's perspective, inform user that the genes in verified_gene list are calculated by SCENIC and has been proven by experiment that can be regulated by transcription factor. 
        2. Inform user that other gene, which are not in verified_gene but in regulon, might be regulated by transcription factor. They need experiment to verify this regulatory relationship.
        3. Whole analysis can be interpreted from multiple angles, such as the details of this transcription factor, the details of proven genes, the function of this TF-Regulon, and so on. Give details as much as you can.
        4. Avoiding to print all the user input content, take more attention into analysis.
        
        ###Question###: %s
        """ %(tf_list, verified_gene, regulon, question)

    elif u_prompt is None and sub_task is not None:
        prompt = """###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

        ###Task###: Base on user's mission:%s, provide your analyse and advices.

        ###Context###: There are three input list: #tf_list#:%s contains the name of the transcription factor most involved in gene regulatory network.
        #verified_gene#:%s contains the gene name from regulon but also has been proven by experiment that can be regulated by transcription factor.
        #regulon#:%s contains all gene names calculated by SCENIC method that might be regulated by transcription factor.

        ###Instructions###:
        1. From a biologist's perspective, use provided information to resolve user's question.
        2. Inform user that the genes in verified_gene list are calculated by SCENIC and has been proven by experiment that can be regulated by transcription factor. 
        3. Inform user that other gene, which are not in verified_gene but in regulon, might be regulated by transcription factor. They need experiment to verify this regulatory relationship.
        4. Focus on task and whole analysis can be interpreted from multiple aspects to analyse task, such as the details of this transcription factor in user's mission, the details of proven genes in user's mission, the function of this TF-Regulon in user's mission, and so on. Give details as much as you can.
        5. Avoiding to print all the user input content, take more attention into analysis, give more explanation about your analyse instead of only saying vague words.

        ###Question###: %s
        """ %(sub_task, tf_list, verified_gene, regulon, question)

    elif u_prompt is not None and sub_task is None:
        prompt = u_prompt % (tf_list, verified_gene, regulon, question)
    else:
        prompt = u_prompt % (sub_task, tf_list, verified_gene, regulon, question)

    result = llm_answer(prompt,question)
    return result

def paga_adviser(adata, u_question=None):
    """
    Provides data analysis suggestions based on Partition-based Graph Abstraction (PAGA).

    This function analyzes the PAGA computation results in `adata` and offers next-step analysis recommendations based on cell trajectory data. 
    It examines the structure of `adata.uns["paga"]["connectivities_tree"]` to determine whether the data should be split into multiple groups 
    and suggests reasonable threshold values for splitting.

    Args:
        adata (AnnData): An AnnData object containing PAGA results computed using `scanpy.tl.paga()`.
        u_question (str, optional): A user-defined question. Defaults to "After running PAGA, what should I do next with my adata?" if not provided.

    Raises:
        ValueError: 
            - If `adata.uns` does not contain the `paga` key, an error is raised, instructing the user to run `sc.tl.paga()` first.
            - If `adata.uns["paga"]` lacks the `connectivities_tree` key, an error is raised, prompting the user to check the data.

    Returns:
        str: Analysis suggestions based on the PAGA computation results.
    """
    if u_question is None:
        question = "What should I do in next step with this adata after running paga."
    else:
        question = translator(u_question)

    if "paga" not in adata.uns.keys():
        raise ValueError("Not found key value 'paga' in your data, run sc.tl.paga() at first.")
    if "connectivities_tree" not in adata.uns["paga"].keys():
        raise ValueError(f"Not found key value 'connectivities_tree' in your data.uns['paga'], check your data at first.")

    paga_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: Use all provided data to give an advice/suggestion to user for helping user understand what he needs to do in next step while he traiting the trajectory of cell development. Write as much as you can, do not write the operations you are going to perform;

    ###Instructions###:
    1. User has already running scanpy.tl.paga() for observing the cell development trajectory graph, you should first analyse the connectivities data in adata: %s like adata.uns['paga']['connectivities'].
    2. Then you should analyse the connectivities data in adata.uns['paga']['connectivities_tree']: %s .
    3. An array type of adata.uns['paga']['connectivities_tree']: %s is also provided by user. 
    4. Give him an advice like try to split his data in some groups or not, if yes, we hope each group can be meaningful, so the threshold number is important.
    5. From a biologist's perspective, base on your advice to provide your raison for why user should split or not split his adata into specific groups, if user need to split his data, give him a number as his threshold. 

    ###Example 1###: By checking your data, you can set this number (such as O.05) as your threshold to split your adata into some groups.
    ###Example 2###: Based on the provided data and the connectivities matrix from your AnnData object, it's evident that you are examining the cell development trajectory graph using PAGA (Partition-based Graph Abstraction).  The connectivities data in `adata. uns['paga']['connectivities_tree']` indicates the strength of connections between different cell groups. 
    Here are some observations and suggestions for your next steps:
        ### Analysis of Connectivities Data
        ### Suggestions
        ### Grouping and Biological Interpretation
        ### Biological Rationale
        ### Next Steps
    By following these steps, you will be able to split your data into meaningful groups and gain insights into the cell development trajectory. Setting a threshold of 0.05 for your connectivities will help you to filter out noise and focus on biologically relevant connections.
    ###Question###: %s
    """ %(adata,adata.uns["paga"]["connectivities_tree"],adata.uns["paga"]["connectivities_tree"].toarray(), question)
    
    result = llm_answer(paga_prompt,question)
    return result

def analyse_general_trajectory(trajectory_graph, u_question=None):
    """
    Performs a global analysis of the input cell developmental trajectory graph and provides a biological interpretation.

    This function analyzes the cell developmental trajectory from multiple perspectives, such as cells, genes, and pathways, 
    and generates a comprehensive explanatory report. Instead of describing pairwise relationships between cell types in isolation, 
    it integrates various biological interpretations into a cohesive narrative.

    Args:
        trajectory_graph (networkx.Graph): A NetworkX graph representing the cell developmental trajectory.
        u_question (str, optional): A user-defined question. If not provided, the default question is:
                                    "Provide a comprehensive interpretation of the input cell developmental trajectory 
                                    from the perspectives of cells, genes, and pathways. When describing developmental 
                                    trajectories between cell types, avoid presenting individual data points separately. 
                                    Instead, integrate multiple biological explanations, such as involved genes, pathways, 
                                    and regulatory mechanisms, into a coherent paragraph."

    Raises:
        ValueError: If `trajectory_graph` is empty or lacks valid edges and node data, an error may be raised.

    Returns:
        str: An AI-generated analysis report on the cell developmental trajectory.
    """
    if u_question is None:
        question = "Provide a global interpretation of the input cell developmental trajectory graph from perspectives such as cells and genes. When explaining the developmental trajectory between each pair of cell types, avoid presenting the points separately. Instead, integrate different biological interpretation angles—such as genes involved, pathways, and regulatory mechanisms—into a cohesive narrative described in a single paragraph."
    else:
        question = translator(u_question)

    trajectory_paths = [(source, target, attributes.get("color", None)) for source, target, attributes in trajectory_graph.edges(data=True)]
    trajectory_nodes = [(node, attr.get('shape', None), attr.get('color', None)) for node, attr in trajectory_graph.nodes(data=True)]


    general_prompt2 = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: Use the provided information to write a global analysis about the trajectory of cell development. Write as much as you can, do not write the operations you are going to perform;

    ###Context###: 
    1. User has a cell development trajectory graph, obtained as follows: 1) The trajectory inference used the PAGA algorithm to obtain the PAGA results. 2) Then, by referencing node pairs that appear in the PAGA results within our biological knowledge graph, we supplemented the PAGA results, ultimately constructing the input graph.
    2. In this graph, the following information can be obtained: 1) Circular/Ellipse nodes represent data from the original RNAseq dataset, and gray hexagonal nodes represent data from our biological knowledge graph; 2) Green edges with arrows represent developmental trajectories that can be found in the knowledge graph, while red edges without arrows represent developmental trajectories that are not recorded in the graph but were inferred by the PAGA algorithm from the actual dataset.
    3. The user will input a list of paths which are extracted from this graph: %s and a list of nodes which consist these paths: %s, use it to analyse graph.

    ###Instructions###:
    1. From a biologist's perspective, provide an overall and then detailed analysis of the given paths for the graph. The analysis can interpret the developmental relationships between cells from multiple angles, such as the location of development, key genes involved, and developmental pathways, give details as much as you can.

    ###Example###: In order to understand this trajectory of cell development from the perspective of regulatory genes and signaling pathways, we need to interpret these developmental pathways in combination with key gene regulatory networks and signaling pathways during cell differentiation. The complexity of cell differentiation depends on multiple levels of gene expression regulation and cell signaling, molecular mechanisms that ensure that each cell differentiates along the correct developmental path and performs its corresponding function. 
    
    ###Question###: %s
    """ %(trajectory_paths,trajectory_nodes,question)

    general_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: Use the provided information to write a global analysis about the trajectory of cell development. Write as much as you can, do not write the operations you are going to perform;

    ###Context###: The user input a list of paths which are extracted from this graph: {path} and a list of nodes which consist these paths: {node}, use it to analyse graph.
    1. User has a cell development trajectory graph, obtained as follows: 1) The trajectory inference used the PAGA algorithm to obtain the PAGA results. 2) Then, by referencing node pairs that appear in the PAGA results within our biological knowledge graph, we supplemented the PAGA results, ultimately constructing the input graph.
    2. In this graph, the following information can be obtained: 1) Circular/Ellipse nodes represent data from the original RNAseq dataset, and gray hexagonal nodes represent data from our biological knowledge graph; 2) Green edges with arrows represent developmental trajectories that can be found in the knowledge graph, while red edges without arrows represent developmental trajectories that are not recorded in the graph but were inferred by the PAGA algorithm from the actual dataset.

    ###Instructions###:
    1. From a biologist's perspective, provide an overall and then detailed analysis of the given paths for the graph. The analysis can interpret the developmental relationships between cells from multiple angles, such as the location of development, key genes involved, and developmental pathways, give details as much as you can.

    ###Example###: In order to understand this trajectory of cell development from the perspective of regulatory genes and signaling pathways, we need to interpret these developmental pathways in combination with key gene regulatory networks and signaling pathways during cell differentiation. The complexity of cell differentiation depends on multiple levels of gene expression regulation and cell signaling, molecular mechanisms that ensure that each cell differentiates along the correct developmental path and performs its corresponding function. 
    
    ###Question###: {question}
    """
    model = get_llm()
    prompt = ChatPromptTemplate.from_template(general_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"path": RunnableLambda(lambda _: trajectory_paths), "node": RunnableLambda(lambda _: trajectory_nodes),"question": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    #result = llm_answer(general_prompt,question)
    return result

def analyse_specific_trajectory(trajectory_graph,source,target):
    """
    Analyzes a specific developmental trajectory from the source node to the target node in the given cell trajectory graph 
    and provides a biological interpretation.

    This function explains the developmental trajectory from the perspectives of cells, genes, and signaling pathways. 
    It explores the developmental relationships between cells and integrates existing knowledge for an in-depth analysis.

    Args:
        trajectory_graph (networkx.Graph): A NetworkX graph representing the cell developmental trajectory.
        source (str): The starting node of the trajectory, representing the initial cell type or state.
        target (str): The target node of the trajectory, representing the final cell type or state.

    Raises:
        ValueError: If `source` or `target` is not present in `trajectory_graph`, an error is raised.

    Returns:
        str: An AI-generated analysis report on the specified cell developmental trajectory.
    """
    trajectory_paths = [(source, target, attributes.get("color", None)) for source, target, attributes in trajectory_graph.edges(data=True)]
    trajectory_nodes = [node for node in trajectory_graph.nodes]
    if source not in trajectory_nodes:
        raise ValueError("Your input source node is not in your trajectory grpah.")
    if target not in trajectory_nodes:
        raise ValueError("Your input target node is not in your trajectory graph.")

    question = f"How to interpret the developmental path from {source} to {target}, find their relationship (must be represented by the path in the incoming graph) and use your knowledge to further explain the developmental relationship from the level of cells, genes, etc."

    specific_prompt2 = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: Use the provided information and your own knowledge to write a analysis about the query trajectory of cell development. Write as much as you can, do not write the operations you are going to perform;

    ###Context###: Here user provides whole trajectory paths of cell development: %s, use it to search the specific path from source node: %s to target node: %s, and then give an explanation.
    
    ###Instructions###: From a biologist's perspective, provide detailed analysis of the queried trajectory path from source node to target node. The analysis need to interpret the developmental relationships between these cells from multiple angles, such as the location of development, key genes involved, and developmental pathways, give details as much as you can.

    ###Example###:
    1. from Dendritic Cell to Plasmacytoid Dendritic Cell:
    From previous trajectory we can find out the Dendritic Cell can develop into Plasmacytoid Dendritic Cell, and this path was green which means it can be found in our knowledge graph. Here we shows more details about this trajectory.
    Plasmacytoid dendritic cells are regulated by IRF7 and IRF8, and they are specialized in producing large amounts of type I interferons, particularly playing a crucial role in antiviral immunity. The TLR (Toll-like receptor) signaling pathway, especially TLR7 and TLR9, activates these dendritic cells by recognizing viral RNA or DNA, initiating interferon production, which subsequently triggers the antiviral response via the STAT1/STAT2 signaling pathway.
    
    2. from Myeloid Leukocyte to Myeloid Suppressor Cell:
    From previous trajectory we can find out the Myeloid Leukocyte can develop into Myeloid Suppressor Cell, and this path was green which means it can be found in our knowledge graph. Here we shows more details about this trajectory.
    The differentiation of myeloid-derived suppressor cells (MDSCs) is particularly common in the tumor microenvironment, where these cells help tumors evade immune surveillance by suppressing immune responses. Their differentiation is regulated by the STAT3 and STAT6 signaling pathways, which are activated by immunosuppressive cytokines such as IL-6 and IL-10. This activation leads to the acquisition of functions that suppress T-cell and natural killer cell activity.
    
    ###Question###: %s
    """ %(trajectory_paths, source, target, question)

    specific_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: Use the provided information and your own knowledge to write a analysis about the query trajectory of cell development. Write as much as you can, do not write the operations you are going to perform;

    ###Context###: Here user provides whole trajectory paths of cell development: {context}
    
    ###Instructions###: 1. From a biologist's perspective, provide detailed analysis of the queried trajectory path from source node to target node. The analysis need to interpret the developmental relationships between these cells from multiple angles, such as the location of development, key genes involved, and developmental pathways, give details as much as you can.
                        2. When you analyze the red pathway, you need to let the user notice that this pathway is calculated by PAGA but not verified, and he should pay attention to this pathway and further explore the rationality of this pathway through analysis such as gene regulatory network.
    
    ###Example###:
    1. from Dendritic Cell to Plasmacytoid Dendritic Cell:
    From previous trajectory we can find out the Dendritic Cell can develop into Plasmacytoid Dendritic Cell, and this path was green which means it can be found in our knowledge graph. Here we shows more details about this trajectory.
    Plasmacytoid dendritic cells are regulated by IRF7 and IRF8, and they are specialized in producing large amounts of type I interferons, particularly playing a crucial role in antiviral immunity. The TLR (Toll-like receptor) signaling pathway, especially TLR7 and TLR9, activates these dendritic cells by recognizing viral RNA or DNA, initiating interferon production, which subsequently triggers the antiviral response via the STAT1/STAT2 signaling pathway.
    
    2. from Myeloid Leukocyte to Myeloid Suppressor Cell:
    From previous trajectory we can find out the Myeloid Leukocyte can develop into Myeloid Suppressor Cell, and this path was green which means it can be found in our knowledge graph. Here we shows more details about this trajectory.
    The differentiation of myeloid-derived suppressor cells (MDSCs) is particularly common in the tumor microenvironment, where these cells help tumors evade immune surveillance by suppressing immune responses. Their differentiation is regulated by the STAT3 and STAT6 signaling pathways, which are activated by immunosuppressive cytokines such as IL-6 and IL-10. This activation leads to the acquisition of functions that suppress T-cell and natural killer cell activity.
    
    ###Question###: {question}
    """
    model = get_llm()
    prompt = ChatPromptTemplate.from_template(specific_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": RunnableLambda(lambda _: trajectory_paths), "question": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    #result = llm_answer(specific_prompt,question)
    return result


def generate_BRICK_pipeline(u_question, vectorstore='./vectorstore/BRICK_notebook.faiss', search_k=2):
    """
    Generates BRICK code snippets tailored to the user's requirements.

    This function searches the FAISS vector database for example BRICK tool code snippets and generates 
    corresponding Python code based on the user's query. BRICK is a bioinformatics analysis tool built 
    on biomedical knowledge graphs, comprising four core modules:

    1. **BRICK.qr**: Queries the knowledge graph.
    2. **BRICK.rk**: Ranks query results.
    3. **BRICK.emb**: Performs representation learning on graph structures integrating omics data and the knowledge graph.
    4. **BRICK.inp**: Uses LLMs (large language models) combined with prior knowledge to interpret omics analysis results.

    Args:
        u_question (str): The user’s query describing the required BRICK code generation.
        vectorstore (str, optional): Path to the FAISS vector database file (default: `'./vectorstore/BRICK_notebook.faiss'`), 
            used to retrieve BRICK example code.
        search_k (int, optional): The number of similar examples to retrieve from the vector database (default: `2`).

    Returns:
        str: The generated Python code, ready for use in a BRICK analysis pipeline.
    """
    model = get_llm()
    embedding_model = get_llm_embedding()
    u_question = translator(u_question)

    db = FAISS.load_local(vectorstore, embeddings=embedding_model, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={"k": search_k})

    template = """
    ###Role###: You are an excellent Bioinfomnatics assistant, skilled in analysing result for various omics analysis tasks. BRICK is a toolkit in python that interprete the result of analysis using a biomedical knowledge graph. 
    BRICK is composed by 4 module: 
    1. query knowledge graph (BRICK.qr); 
    2. rank queries (BRICK.rk); 
    3. representive leanrning for graph composed by both omics and knowledge graph (BRICK.emb)
    4. use LLM to summarize and interprete the omics result with prior knowledge (BRICK.inp)

    ###Task###: Generate python code to meet user's question according to Context. the Context are serveral notebook provide example for how to use BRICK. Please only keep core code and ignore personalized codes and those used to display variables.

    ###Question###: {question}

    ###Context###:
    {context}    
    """
    prompt = ChatPromptTemplate.from_template(template)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": retriever, "question": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    BRICK_code = chain.invoke(u_question)
    return BRICK_code

def generate_BRICK_code(u_question, vectorstore='./vectorstore/BRICK_code.faiss', search_k=2):
    """
    Generates BRICK code snippets based on user requirements.

    This function searches the FAISS vector database for BRICK code examples and automatically 
    generates executable Python code according to the user's input query. BRICK is a bioinformatics 
    analysis tool based on biomedical knowledge graphs, consisting of four core modules:

    1. **BRICK.qr**: Queries the knowledge graph.
    2. **BRICK.rk**: Ranks query results.
    3. **BRICK.emb**: Performs graph representation learning by integrating omics data with the knowledge graph.
    4. **BRICK.inp**: Utilizes LLMs (large language models) combined with prior knowledge to interpret omics analysis results.

    Args:
        u_question (str): The user's query describing the required BRICK code generation.
        vectorstore (str, optional): Path to the FAISS vector database file (default: `'./vectorstore/BRICK_code.faiss'`), 
            used to retrieve BRICK code examples.
        search_k (int, optional): The number of similar examples to retrieve from the vector database (default: `2`).

    Returns:
        str: The generated Python code, ready for use in a BRICK analysis pipeline.
    """
    model = get_llm()
    embedding_model = get_llm_embedding()
    u_question = translator(u_question)

    db = FAISS.load_local(vectorstore, embeddings=embedding_model, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={"k": search_k})

    template = """
    **Role**: You are an expert Bioinformatics assistant skilled in analyzing omics data using the BRICK toolkit. 
    Your goal is to generate executable Python code that integrates with BRICK modules.

    **Toolkit Overview**:
    BRICK is a toolkit in python that interprete the result of analysis using a biomedical knowledge graph. It consists of 4 core modules:
    1. `BRICK.qr` - Knowledge graph querying
    2. `BRICK.rk` - Query ranking
    3. `BRICK.emb` - Graph representation learning for the graph that composed by both omics and knowledge graph
    4. `BRICK.inp` - LLM-powered interpretation for the omics result with prior knowledge

    **User Question**:
    {question}

    **Context**:
    {context}
    
    **Task Requirements**:
    1. **Code Generation**: 
    - Create Python code addressing the user's question using the provided context
    - Ensure complete function calls including module paths
    - Add necessary imports and environment setup if provided context contains these details

    2. **Function Completion**:
    - Identify source modules from function context
    - Format calls as `ModulePath.FunctionName` (e.g., use `BRICK.pp.config_llm_embedding` is better than use `from BRICK.pp import config_llm_embedding`)
    - Must comply with the function requirements defined in BRICK and Python syntax logic

    3. **Usage Guidance**:
    - Provide tips base on the function description
    - Note potential integration points with other modules

    4. **Other Considerations**:
    - Avoid printing this template content, such as the toolkit overview and your role.
    - Focus on how to use the BRICK functions effectively and efficiently to address the user's question.

    **Example Scenario**:
    User Input: "How to configure LLM when using BRICK?"
    Context Function: `config_llm` in BRICK `_settings.py` file
    - Complete Call: `BRICK.config_llm()`
    - Advice: eg., "Ensure API keys are set in environment variables before initialization"
    """
    prompt = ChatPromptTemplate.from_template(template)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": retriever, "question": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    BRICK_code = chain.invoke(u_question)
    return BRICK_code

def BRICK_helper(u_question, vectorstore_c='./vectorstore/BRICK_code.faiss', vectorstore_n='./vectorstore/BRICK_notebook.faiss', search_k=2):
    """
    Generates an executable solution for the user's question by combining BRICK toolkit code and Jupyter Notebook context.

    This function uses the BRICK toolkit and relevant Jupyter Notebook documentation to provide a Python code snippet 
    that answers the user's query. It retrieves relevant code examples and documentation from the FAISS vector databases 
    and integrates them into a solution. The final output combines both code and documentation to ensure a comprehensive answer.

    Args:
        u_question (str): The user's query that describes the required BRICK code generation.
        vectorstore_c (str, optional): Path to the FAISS vector database file containing BRICK code examples 
            (default: `'./vectorstore/BRICK_code.faiss'`).
        vectorstore_n (str, optional): Path to the FAISS vector database file containing Jupyter Notebook context 
            (default: `'./vectorstore/BRICK_notebook.faiss'`).
        search_k (int, optional): The number of similar examples to retrieve from each vector database (default: `2`).

    Returns:
        str: The generated Python code, along with relevant documentation, that can be directly used in the BRICK analysis pipeline.

    Raises:
        ValueError: If the input vectors or necessary components for code retrieval are not found.
    """

    u_question = translator(u_question)
    template = """
    **Role**: You are an expert Bioinformatics assistant skilled in analyzing omics data using the BRICK toolkit. 
    Your goal is to generate executable Python code that integrates with BRICK modules.

    **Toolkit Overview**:
    BRICK is a toolkit in python that interprete the result of analysis using a biomedical knowledge graph. It consists of 4 core modules:
    1. `BRICK.qr` - Knowledge graph querying
    2. `BRICK.rk` - Query ranking
    3. `BRICK.emb` - Graph representation learning for the graph that composed by both omics and knowledge graph
    4. `BRICK.inp` - LLM-powered interpretation for the omics result with prior knowledge
    
    **User Question**:
    {question}

    **Context**: We retrieved the following relevant information from the code base:
    1. [Python code base]: {py_context}
    2. [Jupyter Notebook document]: {ipynb_context}

    **Task Requirements**:
    1. **Analyze whether the two parts are consistent** (if there is a contradiction, please point it out)
    2. **Combining code & documentation, provide the best solution**
    3. **Only answer based on the content provided, do not make up information! **
    4. **Provide a clear and concise answer**
    """
    prompt = ChatPromptTemplate.from_template(template)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"py_context": RunnableLambda(lambda q: generate_BRICK_code(u_question, vectorstore_c, search_k)), "ipynb_context": RunnableLambda(lambda q: generate_BRICK_pipeline(u_question, vectorstore_n, search_k)), "question": RunnablePassthrough()}
    )
    model = get_llm()
    chain = setup_and_retrieval | prompt | model | output_parser
    BRICK_code = chain.invoke(u_question)
    return BRICK_code

def translator(u_question):
    """
    Translates the user's question into English using a large language model (LLM).

    This function takes the user's input question and uses a pre-trained LLM to translate it into English. 
    The language model processes the input text and returns the translated question.

    Args:
        u_question (str): The question provided by the user that needs to be translated.

    Returns:
        str: The translated version of the user's question.

    Raises:
        ValueError: If the translation process encounters an error.
    """
    template = """
    ###Role###: You are a professional translator, skilled in translating text from one language to English.

    ###Task###: Translate the user's question into English.

    ###Context###: The user has provided the following question in the source language: {question}

    ###Instructions###: 1. Determine whether the user's question is in English. If not, translate the question into English and return it to the user. Ensure that the translation is accurate and maintains the original meaning of the question.
                        2. Only return the translated question to the user, without any additional information or comments.
    """
    prompt = ChatPromptTemplate.from_template(template)
    output_parser = StrOutputParser()
    model = get_llm()
    chain = prompt | model | output_parser
    translated_question = chain.invoke(u_question)
    return translated_question


def differetial_expression_gene_inspector(DEG_df, query_df, selected_cell_type='', u_question=None):
    """
    """
    if u_question is None:
        question = "Please interprete the differential expression gene result base on the DEG table1 and knowledge queried table2."
    else:
        question = translator(u_question)

    if selected_cell_type != '':
        selected_cell_type = f'of {selected_cell_type} '

    DEG_df_filtered = DEG_df.loc[(DEG_df['scores'] > 0) & (DEG_df['pvals_adj'] < 0.05)]
    query_df_filtered = query_df[['path.0.name', 'path.1', 'path.2.name']]

    general_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: you are analysing the Differetial Expression Gene(DEG) of {selected_cell_type}. you have DEG result in Table1 and you have check a knowledge graph get related knowledges of these DEGs in Table2. Please interprete the DEG result;

    ###Context###: 
    Please interprete the DEG result from 2 aspects: 
    1. Inspect the result and summary valuable findings and conclusions; 
    2. Advice following analysis and interpreter steps and reseach object. 
    Table1:
    {DEG_df}

    Table2: 
    {query_df}

    ###Question###: {question}
    """

    model = get_llm()
    prompt = ChatPromptTemplate.from_template(general_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"selected_cell_type": RunnableLambda(lambda _: selected_cell_type),
         "DEG_df": RunnableLambda(lambda _: DEG_df_filtered),
         "query_df": RunnableLambda(lambda _: query_df_filtered),
         "question": RunnableLambda(lambda _: question), }
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    # result = llm_answer(general_prompt,question)
    return result

def gene_enrichment_analysis(query_target_df, gene_cluster, selected_cell_type='', u_question=None):
    """
    """
    if u_question is None:
        question = "Please interprete the gene_enrichment result base on the enriched table1 and enriched table2 for gene sub-clusters if table2 available."
    else:
        question = translator(u_question)

    if selected_cell_type != '':
        selected_cell_type = f'of {selected_cell_type} '

    query_target_df_sub = query_target_df.loc[query_target_df['path.2.enrich_pvalue'] < 0.05]
    query_target_df_sub = query_target_df_sub.sort_values(by=['path.2.enrich_pvalue'], ascending=[True])

    query_target_df_sub_filtered = query_target_df_sub.groupby('path.2.type').head(20)[
        ['path.0.name', 'path.2.name', 'path.2.match_count', 'path.2.enrich_pvalue']]

    all_df = []
    for x, y in gene_cluster.obs.groupby('leiden'):
        genelist = list(y.index)
        #print(len(genelist))
        query_target_df_sub['sub_cluster_match_count'] = [len(set(i) & set(genelist)) for i in
                                                          query_target_df_sub['path.0.name']]

        query_target_df_sub_leiden = query_target_df_sub.sort_values(
            by=['sub_cluster_match_count', 'path.2.enrich_pvalue'], ascending=[False, True])
        query_target_df_sub_leiden.loc[query_target_df_sub_leiden['sub_cluster_match_count'] > 0]
        query_target_df_sub_leiden = query_target_df_sub_leiden.groupby('path.2.type').head(5)
        query_target_df_sub_leiden['leiden'] = x
        all_df.append(query_target_df_sub_leiden)

    all_df = pd.concat(all_df)
    all_df = all_df[['path.0.name', 'path.2.name', 'sub_cluster_match_count', 'leiden']]
    all_df.columns = ['path.0.name', 'path.2.name', 'sub_cluster_match_count', 'gene sub-cluster']

    Table2 = f'Table2:\n {all_df}'


    general_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: you are analysing the gene enrichment {selected_cell_type}. You have enriched result in Table1. Please interprete the enrichment result. You might also get a enrichment result based on gene sub-cluster of original enrichment in Table2. If so, interprete each gene cluster as well.

    ###Context###: 
    Please interprete the enrichment result from 2 aspects: 
    1. Inspect the result and summary valuable findings and conclusions; 
    2. If Table2 is provided, interpreter valuable finds for each gene sub-cluster, respectively.  

    Table1:
    {query_target_df_sub_filtered}
 
    {Table2}

    ###Question###: {question}
    """

    model = get_llm()
    prompt = ChatPromptTemplate.from_template(general_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"query_target_df_sub_filtered": RunnableLambda(lambda _: query_target_df_sub_filtered),
         "Table2": RunnableLambda(lambda _: Table2),
         "question": RunnableLambda(lambda _: question),
         "selected_cell_type": RunnableLambda(lambda _: selected_cell_type)}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    # result = llm_answer(general_prompt,question)
    return result


def cell_annotation_analysis(query_target_df, u_question=None):
    """
    """
    if u_question is None:
        question = "Please interprete the cell annotation result base on the queried table"
    else:
        question = translator(u_question)

    query_target_df = query_target_df.sort_values('path.2.rank_voting', ascending=True).head(5)
    query_target_df = query_target_df[
        ['path.0.name', 'path.2.name', 'path.2.match_count', 'path.2.match_probability', 'path.2.info_source_count',
         'path.2.rank_voting']]

    general_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: you are analysing the cell annotation of a cell cluster. You have queried possible cell type result in queried table. Please interprete the result figure out the most reasonable annotation for this cell cluster and explain why.

    ###Context###: 
    You queried databases according to the differential gene set of this cell cluster. 
    The first column in queried table is genes related to corresponding celltype;
    The second column is candidate cell type;
    The last column is rank for this cell type;
    Other columns are some indicator for ranking of these cell types. 
    Please interprete the annotation result according to following rules: 
    1. Figure out the most reasonable cell type for this cluster and explain why; 
    2. If the there are Subset-Superset Relations between candidate cell types, choose more specific cell type as annotation result.
    3. Judge if this cell cluster might be a mixture of two sub-celltype, if so, and also output these cluster might be a mixture of XXX and XXX cell, recommand user to do sub-cell type refinement for next analysis step.  
    4. Keep the answer brief, no need to output too much thinking process.

    queried table:
    {query_target_df}

    ###Question###: {question}
    """

    model = get_llm()
    prompt = ChatPromptTemplate.from_template(general_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"query_target_df": RunnableLambda(lambda _: query_target_df),
         "question": RunnableLambda(lambda _: question)}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    # result = llm_answer(general_prompt,question)
    return result


def drug_repurposing_analysis(adata_graph, disease_name, df_real_drug=None, u_question=None):
    """
    """
    if u_question is None:
        question = f"Please interprete the drug repurposeing result of {disease_name} base on the table1 and real drug for {disease_name} queried from knowledge graph if 'evidenced_drug' column is available in table1."
    else:
        question = translator(u_question)

    from sklearn.metrics.pairwise import cosine_similarity
    adata_graph_chemical = adata_graph[adata_graph.obs['type'] == 'KG_Chemical']
    adata_graph_disease = adata_graph[adata_graph.obs['name'] == disease_name]

    emb1 = adata_graph_chemical.X
    emb2 = adata_graph_disease.X
    dist = cosine_similarity(emb1, emb2)

    df_drug = adata_graph_chemical.obs.copy()
    df_drug['cosine_similiarity'] = dist
    df_drug = df_drug[['cosine_similiarity']].sort_values('cosine_similiarity', ascending=False)

    if df_real_drug is not None:
        df_drug['evidenced_drug'] = 'False'
        df_drug.loc[df_drug.index.isin(df_real_drug['path.2.name']), 'evidenced_drug'] = True

    df_drug = df_drug.head(100)
    # print(df_drug)
    # return None
    general_prompt = """
    ###Role###: You are an excellent Biology assistant, skilled at writing clear and understandable analysis reports.

    ###Task###: you are analysing the drug repurposing of {disease_name}. You have ranked the candidate drugs based on cosine similiarity between drug and {disease_name} in Table1. Please interprete the drug repurposing result. You might also get a column of 'evidenced_drug' in table1, which indicated the known drug for this disease. If so, try to recommand some candidate drugs without evidence.

    ###Context###: 
    Please interprete the drug repurposing result based on following rules: 
    0. 'name' col in table1 is the name of candidate drug, 'cosine_similiarity' col is the cosine similiarity between {disease_name} and these drugs based on drug repurposing analysis. The drug is ranked based on 'cosine_similiarity' col.
    1. Recommand some possible drugs for {disease_name} based on the table1 and try to explain why this drug might be a possible drug; 
    2. There might be some chemicals that is not drug, ignore these chemicals, do not mention them in output;
    3. If 'evidenced_drug' column in available in table1, You should summary the evidenced drugs with that drug repurposing found breifly. Focus on drug without evidence and try to explain why this drug might be a possible drug.

    table1:
    {df_drug}

    ###Question###: {question}
    """

    model = get_llm()
    prompt = ChatPromptTemplate.from_template(general_prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"df_drug": RunnableLambda(lambda _: df_drug),
         "question": RunnableLambda(lambda _: question),
         "disease_name": RunnableLambda(lambda _: disease_name)}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(question)
    # result = llm_answer(general_prompt,question)
    return result


def interpret_query(task = '', *args, **kwargs):
    if task == '':
        task = "general interpretation"
    
    result = general_interpret(*args, **kwargs)
    prompt = f"""
You are a biomedical terminology analysis expert. Your task is to answer the question in “{{task}}” based on the table provided below.

Input table (which may be a DataFrame/dict/list, etc.):
{{context}}

There are three types of possible questions:
1. What is XXX? eg. What is the gene Isl1?
2. What is the relationship between XXX and XXX? eg. What is the relationship between Isl1 and PP cell?
3. What is the most related XXX to XXX? eg. What is the most related disease to Isl1 cell?
You need to give a clear answer based on the table and the question.
"""
    model = get_llm()
    prompt = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    setup_and_retrieval = RunnableParallel(
        {"context": RunnableLambda(lambda _: result), "task": RunnablePassthrough()}
    )
    chain = setup_and_retrieval | prompt | model | output_parser
    result = chain.invoke(task)
    return result



# def extract_entities_with_llm(user_question):
#     # English prompt for extracting entities and their types from the question
#     prompt = f"""
#     Extract the entities and their types from the following question:
#     Question: "{user_question}"
    
#     Provide the output in this format:
#     source_entity_set: [<entities>]
#     target_entity_set: [<entities>]
    
#     Note: You need to identify the entities and their types based on the question, such as "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
#     """
    
#     model = get_llm()  # Get the LLM model
#     prompt_template = ChatPromptTemplate.from_template(prompt)
#     output_parser = StrOutputParser()
    
#     # Execute the model to generate the result
#     chain = prompt_template | model | output_parser
#     result = chain.invoke()

#     # Return the extracted result
#     return result

# def extract_entities_relation(user_question):
#     # English prompt for extracting entities and their types from the question
#     prompt = f"""
#     Extract the entities and their types from the following question:
#     Question: "{user_question}"
    
#     Provide the output in this format:
#     source_entity_set = ["<entities>"]
#     target_entity_set = ["<entities>"]
    
#     Identify the entities in the question and their types. You should recognize entity types such as:
#     "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
    
#     For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
#     The entities should be listed separately in source_entity_set and target_entity_set as appropriate, formatted exactly as source_entity_set = ["entity1"], target_entity_set = ["entity"].
#     """
    
#     model = get_llm()  # Get the LLM model
#     prompt_template = ChatPromptTemplate.from_template(prompt)
#     output_parser = StrOutputParser()
    
#     # Execute the model to generate the result
#     chain = prompt_template | model | output_parser
#     result = chain.invoke({"question": user_question})

#     # Return the extracted result
#     return result

# def extract_entities_node(user_question):
#     # English prompt for extracting entities and their types from the question
#     prompt = f"""
#     Extract the entities and their types from the following question:
#     Question: "{user_question}"
    
#     Provide the output in this format:
#     source_entity_set = ["<entity1>"]
    
#     Identify the entities in the question and their types. You should recognize entity types such as:
#     "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
    
#     For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
#     The entities should be listed separately in source_entity_set in the format exactly as source_entity_set = ["entity1"].
#     """
    
#     model = get_llm()  # Get the LLM model
#     prompt_template = ChatPromptTemplate.from_template(prompt)
#     output_parser = StrOutputParser()
    
#     # Execute the model to generate the result
#     chain = prompt_template | model | output_parser
#     result = chain.invoke({"question": user_question})

#     # Return the extracted result
#     return result

# def extract_entities_neighbor(user_question):
#     # English prompt for extracting entities and their types from the question
#     prompt = f"""
#     Extract the entities and their types from the following question:
#     Question: "{user_question}"
    
#     Provide the output in this format:
#     source_entity_set = ["<entity1>"], 
#     source_entity_type = "<type>",
#     target_entity_type = "<type>"
    
#     Identify the entities in the question and their types. You should recognize entity types such as:
#     "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
    
#     For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
#     The entities should be listed separately in source_entity_set and formatted as source_entity_set = ["entity1"].
#     """
    
#     model = get_llm()  # Get the LLM model
#     prompt_template = ChatPromptTemplate.from_template(prompt)
#     output_parser = StrOutputParser()
    
#     # Execute the model to generate the result
#     chain = prompt_template | model | output_parser
#     result = chain.invoke({"question": user_question})

#     # Return the extracted result
#     return result

import re, ast
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from ._settings import get_llm

# --------- 解析工具：保留你原有的输出格式（等号形式），从字符串里抠出值 ----------
def _extract_list(text: str, key: str):
    """
    从形如 `key = ["A", "B"]` 的文本里抓取列表；若是 `key = "A"` 也能兜底转成 ["A"]。
    """
    # 优先匹配 list 形式
    m = re.search(rf'{re.escape(key)}\s*=\s*(\[[^\]]*\])', text, flags=re.S)
    if m:
        try:
            return ast.literal_eval(m.group(1)) or []
        except Exception:
            pass
    # 其次匹配单字符串形式
    m = re.search(rf'{re.escape(key)}\s*=\s*(".*?"|\'.*?\')', text, flags=re.S)
    if m:
        val = m.group(1)
        try:
            v = ast.literal_eval(val)
            return [v] if isinstance(v, str) else (v or [])
        except Exception:
            return [val.strip('"\'')]
    return []

def _extract_str(text: str, key: str):
    """
    从形如 `key = "Type"` 的文本里抓取字符串；抓不到则返回 None。
    """
    m = re.search(rf'{re.escape(key)}\s*=\s*(".*?"|\'.*?\')', text, flags=re.S)
    if not m:
        return None
    try:
        return ast.literal_eval(m.group(1))
    except Exception:
        return m.group(1).strip('"\'')  # 兜底

# ---------------- 下面三个方法：仅改“返回值”，原 prompt 原样保留 ----------------

# "Protein", "Disease", "Chemical", "Process", "Tissue", "Phenotype", "Cell", "Species", "Function", "Cell_Component", "Stage", "Mutation", "Gene"， "Pathway" 
def extract_entities_relation(user_question):
    # English prompt for extracting entities and their types from the question
    prompt = f"""
    Extract the entities and their types from the following question:
    Question: "{user_question}"
    
    Provide the output in this format:
    source_entity_set = ["<entities>"]
    target_entity_set = ["<entities>"]
    
    Identify the entities in the question and their types. You should recognize entity types such as:
    "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
    
    For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
    The entities should be listed separately in source_entity_set and target_entity_set as appropriate, formatted exactly as source_entity_set = ["entity1"], target_entity_set = ["entity"].
    """
    
    model = get_llm()  # Get the LLM model
    prompt_template = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    
    # Execute the model to generate the result
    chain = prompt_template | model | output_parser
    result = chain.invoke({"question": user_question})

    # ===== 改动点：解析字符串为 Python 值 =====
    source_entity_set = _extract_list(result, "source_entity_set")
    target_entity_set = _extract_list(result, "target_entity_set")
    return source_entity_set, target_entity_set


def extract_entities_node(user_question):
    # English prompt for extracting entities and their types from the question
    prompt = f"""
    Extract the entities and their types from the following question:
    Question: "{user_question}"
    
    Provide the output in this format:
    source_entity_set = ["<entity1>"]
    
    Identify the entities in the question and their types. You should recognize entity types such as:
    "Gene|Protein", "Disease|Phenotype", "Process|Function|Pathway|Cell_Component", "Chemical", "Species", "Cell|Tissue", "Mutation", etc.
    
    For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
    The entities should be listed separately in source_entity_set in the format exactly as source_entity_set = ["entity1"].
    """
    
    model = get_llm()  # Get the LLM model
    prompt_template = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    
    # Execute the model to generate the result
    chain = prompt_template | model | output_parser
    result = chain.invoke({"question": user_question})

    # ===== 改动点：解析为 list =====
    source_entity_set = _extract_list(result, "source_entity_set")
    return source_entity_set


def extract_entities_neighbor(user_question):
    # English prompt for extracting entities and their types from the question
    prompt = f"""
    Extract the entities and their types from the following question:
    Question: "{user_question}"
    
    Provide the output in this format:
    source_entity_set = ["<entity1>"], 
    source_entity_type = "<type>",
    target_entity_type = "<type>"
    
    Identify the entities in the question and their types. You should recognize entity types such as:
    "Protein", "Disease", "Chemical", "Process", "Tissue", "Phenotype", "Cell", "Species", "Function", "Cell_Component", "Stage", "Mutation", "Gene"， "Pathway", etc.
    
    For example, if the question mentions "Isl1 gene" or "BRCA1 mutation", extract "Isl1" as a Gene and "BRCA1" as a Mutation.
    
    The entities should be listed separately in source_entity_set and formatted as source_entity_set = ["entity1"].
    """
    
    model = get_llm()  # Get the LLM model
    prompt_template = ChatPromptTemplate.from_template(prompt)
    output_parser = StrOutputParser()
    
    # Execute the model to generate the result
    chain = prompt_template | model | output_parser
    result = chain.invoke({"question": user_question})

    # ===== 改动点：解析为 (list, str|None, str|None) =====
    source_entity_set = _extract_list(result, "source_entity_set")
    source_entity_type = _extract_str(result, "source_entity_type")
    target_entity_type = _extract_str(result, "target_entity_type")
    return source_entity_set, source_entity_type, target_entity_type
